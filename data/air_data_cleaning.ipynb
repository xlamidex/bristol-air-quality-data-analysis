{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries used\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the file\n",
    "my_file = pd.read_csv('data\\air-quality-data-continuous.csv', sep=';', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data type of each column\n",
    "for col in my_file.columns:\n",
    "    print('column', col,':', type(my_file[col][0]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the columns which had dates to the have the right data type\n",
    "\n",
    "my_file['Date Time'] = my_file['Date Time'].astype('datetime64[ns]')\n",
    "my_file['DateStart'] = my_file['DateStart'].astype('datetime64[ns]')\n",
    "my_file['DateEnd'] = my_file['DateEnd'].astype('datetime64[ns]')\n",
    "\n",
    "for col in my_file.columns:\n",
    "    print('column', col,':', type(my_file[col][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping the dataset\n",
    "\n",
    "checker_date = '2010-01-01 00:00:00'\n",
    "\n",
    "crop_file = my_file[my_file['Date Time'] >= checker_date]\n",
    "\n",
    "#resetting the index of the cropped file\n",
    "  \n",
    "crop_file = crop_file.assign(ID=range(len(crop_file))).set_index('ID')\n",
    "print(crop_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the file by checking two things:\n",
    "\n",
    "#filtering for and remove any dud records where there is no value for SiteID \n",
    "# First I check if it has any empty values\n",
    "print(crop_file['SiteID'].isnull().values.any())\n",
    "\n",
    "#Then I print out the line number for empty fields\n",
    "sid = crop_file['SiteID']\n",
    "for data in sid:\n",
    "    if data is None:\n",
    "       print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering for and removing any dud records where there is a mismatch between SiteID and Location.\n",
    "#Fist, I created two lists of the sites and their corresponding combinations\n",
    "sd = [188, 203,206, 209, 213, 215, 228, 270, 271, 375, 395, 452, 447, 459, 463, 481, 500, 501, 672]\n",
    "lc = ['AURN Bristol Centre', 'Brislington Depot','Rupert Street','IKEA M32','Old Market','Parson Street School','Temple Meads Station','Wells Road','Trailer Portway P&R','Newfoundland Road Police Station',\"Shiner's Garage\",'AURN St Pauls','Bath Road','Cheltenham Road \\ Station Road','Fishponds Road','CREATE Centre Roof','Temple Way','Colston Avenue','Marlborough Street']\n",
    "\n",
    "#Next, I checked for mismatch between 'SiteId' and 'Location' and removed them from the file\n",
    "for index, row in crop_file.iterrows():\n",
    "    if row['SiteID'] in sd:\n",
    "        sd_index = sd.index(row['SiteID'])\n",
    "        lc_value = lc[sd_index]\n",
    "        if row['Location'] != lc_value:\n",
    "            print(index, row['SiteID'], row['Location'])\n",
    "            crop_file = crop_file.drop(index)  \n",
    "    else:\n",
    "        print(index, row['SiteID'], row['Location'])\n",
    "        crop_file = crop_file.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the index in the now clean 'crop file' and renaming it as 'clean_file'\n",
    "\n",
    "clean_file = crop_file.assign(ID=range(len(crop_file))).set_index('ID')\n",
    "print(clean_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
